{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import plotly.graph_objs as goa\n",
    "import matplotlib as mpl\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import copy\n",
    "from itertools import combinations\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from scipy.spatial import ConvexHull\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/Users/jakemendel/Desktop/Code/FeatureFinding\") \n",
    "from FeatureFinding import utils, datasets, models\n",
    "from torch.autograd import grad\n",
    "from typing import Dict, List, Optional, Union, Any, Callable\n",
    "import importlib\n",
    "mpl.style.use('seaborn-v0_8')\n",
    "mpl.rcParams['figure.figsize'] = (15,10)\n",
    "fontsize = 20\n",
    "mpl.rcParams['font.size'] = fontsize\n",
    "mpl.rcParams['xtick.labelsize'] = fontsize\n",
    "mpl.rcParams['ytick.labelsize'] = fontsize\n",
    "mpl.rcParams['legend.fontsize'] = fontsize\n",
    "mpl.rcParams['axes.titlesize'] = fontsize\n",
    "mpl.rcParams['axes.labelsize'] = fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "# your chosen seed\n",
    "chosen_seed = 2\n",
    "utils.set_seed(chosen_seed)\n",
    "\n",
    "#Checking for errors\n",
    "lr_print_rate = 0\n",
    "\n",
    "\n",
    "# Configure the hyperparameters\n",
    "f = 40\n",
    "k = 1\n",
    "n = 2\n",
    "MSE = True #else Crossentropy\n",
    "nonlinearity = utils.relu_plusone\n",
    "tied = True\n",
    "final_bias = True\n",
    "hidden_bias = False\n",
    "unit_weights = False\n",
    "learnable_scale_factor = False\n",
    "initial_scale_factor = 1# (1/(1-np.cos(2*np.pi/f)))**0.5\n",
    "standard_magnitude = False\n",
    "initial_embed = None\n",
    "initial_bias = None\n",
    "\n",
    "\n",
    "epochs = 40000\n",
    "total_epochs = 300000\n",
    "logging_loss = True\n",
    "\n",
    "#Scheduler params\n",
    "max_lr = 20\n",
    "initial_lr = 0.001\n",
    "warmup_frac = 0.05\n",
    "final_lr = 4\n",
    "decay_factor=(final_lr/max_lr)**(1/(total_epochs * (1-warmup_frac)))\n",
    "warmup_steps = int(total_epochs * warmup_frac)\n",
    "\n",
    "\n",
    "store_rate = epochs//400\n",
    "plot_rate=0 #epochs/5\n",
    "\n",
    "\n",
    "# Instantiate synthetic dataset\n",
    "dataset = datasets.SyntheticKHot(f,k)\n",
    "batch_size = len(dataset)//2 #Full batch gradient descent\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle = True, num_workers=0)\n",
    "\n",
    "#Define the Loss function\n",
    "criterion = nn.MSELoss() if MSE else nn.CrossEntropyLoss() \n",
    "\n",
    "# Instantiate the model\n",
    "# initial_embed = torch.tensor(np.array([1/(1-np.cos(2*np.pi/f))**0.5*np.array([np.cos(2*np.pi*i/f),np.sin(2*np.pi*i/f)]) for i in range(f)]),dtype=torch.float32).T * 0.5\n",
    "# initial_bias = -torch.ones(f)*(1/(1-np.cos(2*np.pi/f))- 1)*0.25\n",
    "model = models.Net(f, n,\n",
    "            tied = tied,\n",
    "            final_bias = final_bias,\n",
    "            hidden_bias = hidden_bias,\n",
    "            nonlinearity=nonlinearity,\n",
    "            unit_weights=unit_weights,\n",
    "            learnable_scale_factor=learnable_scale_factor,\n",
    "            standard_magnitude=standard_magnitude,\n",
    "            initial_scale_factor = initial_scale_factor,\n",
    "            initial_embed = initial_embed,\n",
    "            initial_bias = initial_bias)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=initial_lr)\n",
    "\n",
    "#Define a learning rate schedule\n",
    "scheduler = utils.CustomScheduler(optimizer, warmup_steps, max_lr, decay_factor)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "losses, weights_history, model_history = utils.train(model,\n",
    "                                                     loader,criterion,\n",
    "                                                     optimizer,\n",
    "                                                     epochs,\n",
    "                                                     logging_loss,\n",
    "                                                     plot_rate, \n",
    "                                                     store_rate,\n",
    "                                                     scheduler,\n",
    "                                                     lr_print_rate,\n",
    "                                                     dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[1000:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_weights_interactive(weights_history, store_rate=store_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history32 = {k: model.float() for k, model in model_history.items()}\n",
    "post_relu = [model(torch.eye(f)).cpu().detach().numpy() for model in model_history32.values()]\n",
    "post_softmax = [model(torch.eye(f)).softmax(dim=1).cpu().detach().numpy() for model in model_history32.values()]\n",
    "pre_relu = []\n",
    "for model in model_history.values():\n",
    "    out, activations = model(torch.eye(f), hooked=True)\n",
    "    pre_relu.append(activations['unembed_pre'].cpu().detach().numpy())\n",
    "if not MSE:\n",
    "    utils.visualize_matrices_with_slider(post_softmax, store_rate, const_colorbar=True)\n",
    "utils.visualize_matrices_with_slider([p for p in post_relu], store_rate, const_colorbar=True, plot_size = 800)\n",
    "utils.visualize_matrices_with_slider(pre_relu, store_rate, const_colorbar=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featurefinding_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
