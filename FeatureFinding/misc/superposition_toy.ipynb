{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib as mpl\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.style.use('seaborn-v0_8')\n",
    "mpl.rcParams['figure.figsize'] = (15,10)\n",
    "fontsize = 20\n",
    "mpl.rcParams['font.size'] = fontsize\n",
    "mpl.rcParams['xtick.labelsize'] = fontsize\n",
    "mpl.rcParams['ytick.labelsize'] = fontsize\n",
    "mpl.rcParams['legend.fontsize'] = fontsize\n",
    "mpl.rcParams['axes.titlesize'] = fontsize\n",
    "mpl.rcParams['axes.labelsize'] = fontsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define dimensions\n",
    "f = 10  # Input/Output dimensions\n",
    "n = 2   # Hidden layer dimensions\n",
    "\n",
    "# Create synthetic dataset\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, num_samples, f):\n",
    "        self.num_samples = num_samples\n",
    "        self.f = f\n",
    "        self.data = self.generate_data()\n",
    "        \n",
    "    def generate_data(self):\n",
    "        data = torch.zeros((self.num_samples, self.f))\n",
    "        for i in range(self.num_samples):\n",
    "            index = torch.randint(0, self.f, (1,))\n",
    "            data[i, index] = torch.rand(1)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class SyntheticNormalised(Dataset):\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        self.data = self.generate_data()\n",
    "        \n",
    "    def generate_data(self):\n",
    "        return torch.eye(self.f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.f\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, tied = True, final_bias = False, nonlinearity = F.relu, mlps = 0, is_resnet = False, mlp_dim = None):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.mlps = mlps\n",
    "        self.tied = tied\n",
    "        self.final_bias = final_bias\n",
    "        self.is_resnet = int(is_resnet)\n",
    "        self.mlp_dim = hidden_dim if mlp_dim is None else mlp_dim\n",
    "\n",
    "        # Define the input layer (embedding)\n",
    "        self.embedding = nn.Linear(self.input_dim, self.hidden_dim, bias=False)\n",
    "\n",
    "        #Add extra hidden layers\n",
    "        if mlps > 0:\n",
    "            self.hidden = nn.ModuleList([nn.Linear(self.hidden_dim, self.hidden_dim, bias = False) for _ in range(mlps)])\n",
    "        \n",
    "        # Define the output layer (unembedding)\n",
    "        self.unembedding = nn.Linear(self.hidden_dim, self.input_dim, bias=final_bias)\n",
    "\n",
    "        # Tie the weights\n",
    "        if tied:\n",
    "            self.unembedding.weight = torch.nn.Parameter(self.embedding.weight.transpose(0, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        if self.mlps > 0:\n",
    "            for layer in self.hidden:\n",
    "                x = self.nonlinearity(layer(x)) + self.is_resnet * x\n",
    "        x = self.unembedding(x)\n",
    "        x = self.nonlinearity(x)\n",
    "        return x\n",
    "\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, tied = True, final_bias = False, nonlinearity = F.relu, mlps = 0, is_resnet = False, mlp_dim = None):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.mlps = mlps\n",
    "        self.tied = tied\n",
    "        self.final_bias = final_bias\n",
    "        self.is_resnet = int(is_resnet)\n",
    "        self.mlp_dim = hidden_dim if mlp_dim is None else mlp_dim\n",
    "\n",
    "\n",
    "        # Define the input layer (embedding)\n",
    "        self.embedding = nn.Linear(self.input_dim, self.hidden_dim, bias=False)\n",
    "\n",
    "        #Add extra hidden layers\n",
    "        if mlps > 0:\n",
    "            self.hidden = nn.ModuleList([self.create_mlp_layer() for _ in range(mlps)])\n",
    "        \n",
    "        # Define the output layer (unembedding)\n",
    "        self.unembedding = nn.Linear(self.hidden_dim, self.input_dim, bias=final_bias)\n",
    "\n",
    "        # Tie the weights\n",
    "        if tied:\n",
    "            self.unembedding.weight = torch.nn.Parameter(self.embedding.weight.transpose(0, 1))\n",
    "            \n",
    "    def create_mlp_layer(self):\n",
    "        mlp_layer = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.mlp_dim, bias=False),\n",
    "            self.nonlinearity,\n",
    "            nn.Linear(self.mlp_dim, self.hidden_dim, bias=False)\n",
    "        )\n",
    "        return mlp_layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        if self.mlps > 0:\n",
    "            for layer in self.hidden:\n",
    "                x = self.nonlinearity(layer(x)) + self.is_resnet * x\n",
    "        x = self.unembedding(x)\n",
    "        x = self.nonlinearity(x)\n",
    "        return x\n",
    "\n",
    "class FCNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, mlp_dim, tied = True, final_bias = False, nonlinearity = torch.sigmoid, mlps = 0, is_resnet = False):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.mlp_dim = mlp_dim\n",
    "        self.nonlinearity = nonlinearity\n",
    "        self.mlps = mlps\n",
    "        self.tied = tied\n",
    "        self.final_bias = final_bias\n",
    "        self.is_resnet = int(is_resnet)\n",
    "\n",
    "        # Define the input layer (embedding)\n",
    "        self.embedding = nn.Linear(self.input_dim, self.hidden_dim, bias=False)\n",
    "\n",
    "        # Add extra hidden layers\n",
    "        if mlps > 0:\n",
    "            self.hidden_layers = nn.ModuleList([nn.Linear(self.hidden_dim, self.mlp_dim, bias=False) for _ in range(mlps)])\n",
    "            self.hidden_layers_t = nn.ModuleList([nn.Linear(self.mlp_dim, self.hidden_dim, bias=False) for _ in range(mlps)])\n",
    "        \n",
    "        # Define the output layer (unembedding)\n",
    "        self.unembedding = nn.Linear(self.hidden_dim, self.input_dim, bias=final_bias)\n",
    "\n",
    "        # Tie the weights\n",
    "        if tied:\n",
    "            self.unembedding.weight = torch.nn.Parameter(self.embedding.weight.transpose(0, 1))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        if self.mlps > 0:\n",
    "            for layer, layer_t in zip(self.hidden_layers, self.hidden_layers_t):\n",
    "                x = layer(x)\n",
    "                x = self.nonlinearity(x)\n",
    "                x = layer_t(x) + self.is_resnet * x\n",
    "        x = self.unembedding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def plot_weights(weight_matrix, jitter = 0.05, normalised = False, save = False, epoch = None):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for i in range(weight_matrix.shape[0]):\n",
    "        normalisation = (weight_matrix[i,0]**2 + weight_matrix[i,1]**2) **0.5 if normalised else 1 \n",
    "        plt.arrow(0, 0, weight_matrix[i,0]/normalisation, weight_matrix[i,1]/normalisation, head_width=0.05, head_length=0.1, fc='blue', ec='blue')\n",
    "        plt.text(weight_matrix[i,0]/normalisation + jitter * torch.randn(1), weight_matrix[i,1]/normalisation + jitter * torch.randn(1), f\"{i}\", color='red', fontsize=12)\n",
    "\n",
    "    mins = -1.2 if normalised else weight_matrix.min()-0.5\n",
    "    maxs = 1.2 if normalised else weight_matrix.max()+0.5\n",
    "    plt.xlim(mins,maxs)\n",
    "    plt.ylim(mins,maxs)\n",
    "    plt.grid()\n",
    "    if save:\n",
    "        assert epoch is not None\n",
    "        plt.savefig(f\"weights_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def scaled_sigmoid(scale=1, shift=0):\n",
    "    def output(x):\n",
    "        return scale * (torch.sigmoid(x) + shift)\n",
    "    return output\n",
    "\n",
    "def normalise(matrix, tolerance = 1e-10):\n",
    "    out = np.zeros_like(matrix)\n",
    "    for i,row in enumerate(matrix):\n",
    "        norm = (row.T @ row) ** 0.5\n",
    "        if norm > tolerance:\n",
    "            out[i] = row / norm\n",
    "        else:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def np_relu(matrix):\n",
    "    return np.maximum(matrix,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using_wandb = False\n",
    "logging_loss = True\n",
    "new_run = True\n",
    "\n",
    "# Configure the hyperparameters\n",
    "f = 50\n",
    "n = 2\n",
    "batch_size = f\n",
    "epochs = 20000\n",
    "learning_rate = 5\n",
    "image_store_rate = epochs/1000\n",
    "plot_rate=epochs/5\n",
    "nonlinearity =  nn.GELU()\n",
    "tied = False\n",
    "final_bias = False\n",
    "hidden_layers = 1\n",
    "is_resnet = True\n",
    "\n",
    "# Start a new run\n",
    "if using_wandb:\n",
    "  run = wandb.init(project=\"tiny_superposition\", entity=\"jake-mendel\")\n",
    "if logging_loss:\n",
    "    if new_run:\n",
    "        if 'model' in globals():\n",
    "            old_model = model#type: ignore\n",
    "        losses = []\n",
    "\n",
    "\n",
    "\n",
    "# print_rate = 5000\n",
    "if using_wandb:\n",
    "    config = wandb.config\n",
    "    f = f\n",
    "    config.n = n\n",
    "    config.batch_size = batch_size\n",
    "    config.epochs = epochs\n",
    "    config.learning_rate = learning_rate\n",
    "    config.image_store_rate = image_store_rate\n",
    "\n",
    "# Instantiate synthetic dataset\n",
    "dataset = SyntheticNormalised(f)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "# Instantiate the model\n",
    "if new_run:\n",
    "    model = FCNet(f, n,\n",
    "                  tied = tied,\n",
    "                  final_bias = final_bias,\n",
    "                  nonlinearity=nonlinearity,\n",
    "                  hidden_layers=hidden_layers,\n",
    "                  is_resnet = is_resnet)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#Define a learning rate schedule\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=epochs//100, gamma=3000**(-100))\n",
    "\n",
    "# Watch the model\n",
    "if using_wandb:\n",
    "  wandb.watch(model)\n",
    "\n",
    "# Training\n",
    "def train(model, loader, criterion, optimizer, epochs):\n",
    "    weights_history = {k:[v.detach().numpy().copy()] for k,v in dict(model.named_parameters()).items()}  # Store the weights here\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        for batch in loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch)\n",
    "            loss = criterion(outputs, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        if using_wandb:\n",
    "            wandb.log({\"epoch\": epoch, \"loss\": avg_loss})\n",
    "        if logging_loss:\n",
    "           losses.append(avg_loss)\n",
    "           if (epoch + 1) % plot_rate == 0:\n",
    "               plt.figure(figsize = (5,5))\n",
    "               plt.plot(losses)\n",
    "               plt.show()\n",
    "        # if (epoch + 1) % print_rate == 0:\n",
    "        #   print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "        # Every image_store_rate epochs, save weights\n",
    "        if (epoch + 1) % image_store_rate == 0:\n",
    "            for k,v in dict(model.named_parameters()).items():\n",
    "                weights_history[k].append(v.detach().numpy().copy())\n",
    "    scheduler.step()\n",
    "    return weights_history  # Return the weights history\n",
    "\n",
    "# Train the model\n",
    "if new_run:\n",
    "    weights_history = train(model, loader, criterion, optimizer, epochs)\n",
    "else:\n",
    "    w = train(model, loader, criterion, optimizer, epochs)\n",
    "    for k,v in w:\n",
    "        weights_history[k] += v\n",
    "# Close the wandb run\n",
    "if using_wandb:\n",
    "  run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_weights_interactive(weights_history, x_dir = None, y_dir = None, transpose = False):\n",
    "    # Initialize figure\n",
    "    fig = go.Figure()\n",
    "    max_value = np.max([np.abs(weight_matrix).max() for weight_matrix in weights_history])\n",
    "\n",
    "    x_shape = weights_history[0].shape[0] if transpose else weights_history[0].shape[-1]\n",
    "    y_shape = weights_history[0].shape[0] if transpose else weights_history[0].shape[-1]\n",
    "    assert type(x_dir) == type(y_dir)\n",
    "    if isinstance(x_dir, np.ndarray):\n",
    "        assert len(x_dir) == weights_history[0].shape[-1]\n",
    "    if x_dir is None:\n",
    "        x_dir, y_dir = (np.zeros(x_shape), np.zeros(y_shape))\n",
    "        x_dir[0] = 1\n",
    "        y_dir[1] = 1\n",
    "    elif isinstance(x_dir,int):\n",
    "        x = x_dir\n",
    "        y = y_dir\n",
    "        x_dir, y_dir = (np.zeros(x_shape), np.zeros(y_shape))\n",
    "        x_dir[x] = 1\n",
    "        y_dir[y] = 1\n",
    "    else:\n",
    "        if isinstance(x_dir,list):\n",
    "            x_dir = np.array(x_dir)\n",
    "            y_dir = np.array(y_dir)\n",
    "        assert isinstance(x_dir, np.ndarray)\n",
    "        assert len(x_dir) == weights_history[0].shape[-1]\n",
    "    \n",
    "    # Create a scatter plot for each weight matrix\n",
    "    for i, weight_matrix in enumerate(weights_history):\n",
    "        # Convert weight matrix into arrow endpoints and labels\n",
    "        if transpose:\n",
    "            weight_matrix = weight_matrix.T\n",
    "        x_values = weight_matrix @ x_dir\n",
    "        y_values = weight_matrix @ y_dir\n",
    "        labels = list(range(len(x_values)))\n",
    "\n",
    "        # Create scatter plot\n",
    "        scatter = go.Scatter(x=x_values, y=y_values, mode='markers+text', text=labels,\n",
    "                             textposition='top center', marker=dict(size=8), visible = False, name=f'Epoch {i*image_store_rate}')\n",
    "\n",
    "        fig.add_trace(scatter)\n",
    "    \n",
    "    # Make the first scatter plot visible\n",
    "    fig.data[0].visible = True\n",
    "\n",
    "    # Update xaxis and yaxis properties\n",
    "    fig.update_xaxes(title_text='X Value', range=[-max_value*1.1, max_value*1.1])\n",
    "    fig.update_yaxes(title_text='Y Value', range=[-max_value*1.1, max_value*1.1])\n",
    "\n",
    "    # Add a slider to switch between epochs\n",
    "    steps = []\n",
    "    for i in range(len(fig.data)):\n",
    "        step = dict(\n",
    "            method='restyle',\n",
    "            args=['visible', [False] * len(fig.data)],\n",
    "            label=f'Epoch {i * image_store_rate}'\n",
    "        )\n",
    "        step['args'][1][i] = True  # Toggle i'th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "    sliders = [dict(steps=steps, active=0)]\n",
    "\n",
    "    fig.update_layout(sliders=sliders, width=800, height=800)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# plot_weights_interactive(weights_history['unembedding.weight'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights_interactive(weights_history['embedding.weight'], transpose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(k,v[0].shape) for k,v in weights_history.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights_interactive(unembedding_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights_interactive_3d(weights_history, visualisation = 'points', numbering=False):\n",
    "    # Initialize figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Calculate maximum value of all components\n",
    "    max_value = np.max([np.abs(weight_matrix).max() for weight_matrix in weights_history])\n",
    "\n",
    "    # Create a scatter plot for each weight matrix\n",
    "    for i, weight_matrix in tqdm(enumerate(weights_history)):\n",
    "        # Convert weight matrix into arrow endpoints and labels\n",
    "        x_values = weight_matrix[:,0]\n",
    "        y_values = weight_matrix[:,1]\n",
    "        z_values = weight_matrix[:,2]\n",
    "        labels = list(range(len(x_values))) if numbering else ['' for _ in range(len(x_values))]\n",
    "\n",
    "        # Create scatter plot\n",
    "        if visualisation == 'points':\n",
    "            scatter = go.Scatter3d(x=x_values, y=y_values, z=z_values, mode='markers+text', text=labels,\n",
    "                                textposition='middle center', marker=dict(size=4), visible=False, name=f'Epoch {i*image_store_rate}')\n",
    "            fig.add_trace(scatter)\n",
    "        elif visualisation == 'lines':\n",
    "            for j in range(len(x_values)):\n",
    "                # Create arrow body as a line\n",
    "                line = go.Scatter3d(x=[0, x_values[j]], y=[0, y_values[j]], z=[0, z_values[j]], \n",
    "                                    mode='lines',\n",
    "                                    line=dict(width=2, color='blue'),\n",
    "                                    showlegend=False,\n",
    "                                    visible=False)\n",
    "                fig.add_trace(line)\n",
    "\n",
    "    # Make the first scatter plot visible\n",
    "    fig.data[0].visible = True\n",
    "\n",
    "    # Update xaxis, yaxis, and zaxis properties to use the calculated maximum value\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis=dict(range=[-max_value,max_value], title='X Value'),\n",
    "                    yaxis=dict(range=[-max_value,max_value], title='Y Value'),\n",
    "                    zaxis=dict(range=[-max_value,max_value], title='Z Value')))\n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='X Value',\n",
    "                    yaxis_title='Y Value',\n",
    "                    zaxis_title='Z Value'))\n",
    "\n",
    "    # Add a slider to switch between epochs\n",
    "    steps = []\n",
    "    for i in tqdm(range(len(fig.data))):\n",
    "        step = dict(\n",
    "            method='restyle',\n",
    "            args=['visible', [False] * len(fig.data)],\n",
    "            label=f'Epoch {i * image_store_rate}'\n",
    "        )\n",
    "        step['args'][1][i] = True  # Toggle i'th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "    sliders = [dict(steps=steps, active=0)]\n",
    "    fig.update_layout(sliders=sliders, width=800, height=800)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_weights_interactive_3d(embedding_history,'points', False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "import plotly.express as px\n",
    "\n",
    "def generate_colors(n):\n",
    "    color_cycle = cycle(px.colors.qualitative.Plotly)\n",
    "    colors = [next(color_cycle) for _ in range(n)]\n",
    "    return colors\n",
    "\n",
    "\n",
    "def plot_multiple_3d_vectors(vectors_tuple, visualisation = 'points', numbering=False):\n",
    "    # Initialize figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Calculate maximum value of all components\n",
    "    max_value = np.max([np.abs(vector).max() for vectors_list in vectors_tuple for vector in vectors_list])\n",
    "\n",
    "    # Colors for different vectors_list in vectors_tuple\n",
    "    colors = generate_colors(len(vectors_tuple)) if visualisation == 'points' else generate_colors(len(vectors_tuple[0]))\n",
    "\n",
    "    # Create a scatter plot for each list of vectors\n",
    "    for col, vectors_list in zip(colors, vectors_tuple):\n",
    "        for i, vector in tqdm(enumerate(vectors_list)):\n",
    "            # Convert vector into arrow endpoints and labels\n",
    "            if visualisation == 'points':\n",
    "                color = col\n",
    "            else:\n",
    "                color = colors[i]\n",
    "            x_value = vector[0]\n",
    "            y_value = vector[1]\n",
    "            z_value = vector[2]\n",
    "            label = i if numbering else ''\n",
    "\n",
    "            if visualisation == 'lines':\n",
    "                # Create line from origin to point\n",
    "                scatter = go.Scatter3d(x=[0, x_value], y=[0, y_value], z=[0, z_value], mode='lines',\n",
    "                                line=dict(width=2, color=color), showlegend=False)\n",
    "            else:\n",
    "                # Create scatter plot\n",
    "                scatter = go.Scatter3d(x=[x_value], y=[y_value], z=[z_value], mode='markers+text', text=[label],\n",
    "                                textposition='bottom center', marker=dict(size=4, color=color), showlegend=False)\n",
    "\n",
    "            fig.add_trace(scatter)\n",
    "\n",
    "    # Update xaxis, yaxis, and zaxis properties to use the calculated maximum value\n",
    "    fig.update_layout(scene = dict(\n",
    "                        xaxis=dict(range=[-max_value,max_value], title='X Value'),\n",
    "                        yaxis=dict(range=[-max_value,max_value], title='Y Value'),\n",
    "                        zaxis=dict(range=[-max_value,max_value], title='Z Value')))\n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                        xaxis_title='X Value',\n",
    "                        yaxis_title='Y Value',\n",
    "                        zaxis_title='Z Value'))\n",
    "\n",
    "    # Buttons for zooming\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            showactive=False,\n",
    "            buttons=[\n",
    "                dict(label='Original',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1, y=1, z=1))]),\n",
    "                dict(label='2X',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1/2, y=1/2, z=1/2))]),\n",
    "                dict(label='4X',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1/4, y=1/4, z=1/4))]),\n",
    "                dict(label='8X',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1/8, y=1/8, z=1/8))]),\n",
    "                dict(label='16X',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1/16, y=1/16, z=1/16))]),\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    fig.update_layout(updatemenus=updatemenus, width=800, height=800, showlegend = False)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plot_multiple_2d_vectors(vectors_tuple, visualisation = 'points', numbering=False):\n",
    "    #TOFIX\n",
    "    # Initialize figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Calculate maximum value of all components\n",
    "    max_value = np.max([np.abs(vector).max() for vectors_list in vectors_tuple for vector in vectors_list])\n",
    "\n",
    "    # Colors for different vectors_list in vectors_tuple\n",
    "    colors = generate_colors(len(vectors_tuple)) if visualisation == 'points' else generate_colors(len(vectors_tuple[0]))\n",
    "\n",
    "    # Create a scatter plot for each list of vectors\n",
    "    for col, vectors_list in zip(colors, vectors_tuple):\n",
    "        for i, vector in tqdm(enumerate(vectors_list)):\n",
    "            # Convert vector into arrow endpoints and labels\n",
    "            if visualisation == 'points':\n",
    "                color = col\n",
    "            else:\n",
    "                color = colors[i]\n",
    "            x_value = vector[0]\n",
    "            y_value = vector[1]\n",
    "            label = i if numbering else ''\n",
    "\n",
    "            if visualisation == 'lines':\n",
    "                # Create line from origin to point\n",
    "                scatter = go.Scatter(x=[0, x_value], y=[0, y_value], mode='lines',\n",
    "                                line=dict(width=2, color=color), showlegend=False)\n",
    "            else:\n",
    "                # Create scatter plot\n",
    "                scatter = go.Scatter3d(x=[x_value], y=[y_value], mode='markers+text', text=[label],\n",
    "                                textposition='bottom center', marker=dict(size=4, color=color), showlegend=False)\n",
    "\n",
    "            fig.add_trace(scatter)\n",
    "    fig.data[0].visible = True\n",
    "    # Update xaxis, yaxis, and zaxis properties to use the calculated maximum value\n",
    "    fig.update_layout(scene = dict(\n",
    "                        xaxis=dict(range=[-max_value,max_value], title='X Value'),\n",
    "                        yaxis=dict(range=[-max_value,max_value], title='Y Value')))\n",
    "\n",
    "    fig.update_layout(scene = dict(\n",
    "                        xaxis_title='X Value',\n",
    "                        yaxis_title='Y Value'))\n",
    "\n",
    "    # Buttons for zooming\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            showactive=False,\n",
    "            buttons=[\n",
    "                dict(label='Original',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1, y=1))]),\n",
    "                dict(label='2X',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1/2, y=1/2))]),\n",
    "                dict(label='4X',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1/4, y=1/4))]),\n",
    "                dict(label='8X',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1/8, y=1/8))]),\n",
    "                dict(label='16X',\n",
    "                     method='relayout',\n",
    "                     args=['scene.camera', dict(eye=dict(x=1/16, y=1/16))]),\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    fig.update_layout(width=800, height=800, showlegend = False)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Call the function with tuple of lists of vectors\n",
    "# plot_multiple_3d_vectors(([vector_1_1, vector_1_2], [vector_2_1, vector_2_2]), 'points', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = normalise(unembedding_history[-1][:10])\n",
    "b = normalise(embedding_history[-1][:10])\n",
    "\n",
    "plot_multiple_2d_vectors((a,b), 'points', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model(torch.eye(50)).detach().numpy()\n",
    "plt.imshow(a,'RdBu')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = (model.unembedding.weight@model.embedding.weight).detach().numpy()\n",
    "plt.imshow(mat, 'RdBu')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relued = nonlinearity(torch.tensor(embedding_history[-1]@unembedding_history[-1].T)).detach().numpy()\n",
    "prerelu = embedding_history[-1]@unembedding_history[-1].T\n",
    "plt.imshow(prerelu, cmap = 'Blues_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relued = F.relu(torch.tensor(old_model.embedding.weight.T@old_model.unembedding.weight.T)).detach().numpy()\n",
    "prerelu = embedding_history[-1]@unembedding_history[-1].T\n",
    "plt.imshow(relued, cmap = 'Blues_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relued = torch.nn.functional.relu(torch.tensor(embedding_history[-1].T@unembedding_history[-1])).detach().numpy()\n",
    "prerelu = embedding_history[-1].T@unembedding_history[-1]\n",
    "plt.imshow(prerelu, cmap = 'Blues_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.sigmoid(torch.linspace(-5,5,200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(matrix):\n",
    "    out = np.zeros_like(matrix)\n",
    "    for i,row in enumerate(matrix):\n",
    "        norm = (row.T @ row) ** 0.5\n",
    "        out[i] = row / norm\n",
    "    return out\n",
    "\n",
    "def np_relu(matrix):\n",
    "    return np.maximum(matrix,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prods = []\n",
    "normalised = normalise(weights_history[-1])\n",
    "for i,row1 in enumerate(normalised):\n",
    "    rowprods = []\n",
    "    for j,row2 in enumerate(normalised):\n",
    "        if i != j:\n",
    "            rowprods.append(row1.T@row2)\n",
    "    max_prods.append(max(rowprods))\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.hist(max_prods, bins = 1000, log = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods = []\n",
    "normalised = normalise(embedding_history[-1])\n",
    "for i in normalised:\n",
    "    for j in normalised:\n",
    "        prods.append(np.arccos(i.T @ j) * 180/np.pi)\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.hist(prods, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = normalise(unembedding_history[-1])\n",
    "b = normalise(embedding_history[-1])\n",
    "plt.imshow(np_relu(a@b.T), 'Blues_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_vectors(vectors, epsilon):\n",
    "    # Store the groups of similar vectors here\n",
    "    groups = []\n",
    "    norms = []\n",
    "    directions = []\n",
    "\n",
    "    for v in vectors:\n",
    "        # Normalize the current vector\n",
    "        v_norm = v / np.linalg.norm(v)\n",
    "        if np.linalg.norm(v) < 0.01:\n",
    "            continue\n",
    "\n",
    "        # This flag will tell us if the current vector has been added to any group\n",
    "        added_to_group = False\n",
    "\n",
    "        # Go through each existing group to check if this vector belongs there\n",
    "        for i,group in enumerate(groups):\n",
    "            # We use the first vector in the group as representative\n",
    "            group_representative = group[0]\n",
    "            group_representative_norm = group_representative / np.linalg.norm(group_representative)\n",
    "\n",
    "            # Calculate the dot product between the normalized vectors\n",
    "            dot_product = np.dot(v_norm, group_representative_norm)\n",
    "\n",
    "            # Check if the dot product is close enough to 1 (indicating they are scalar multiples of each other)\n",
    "            if np.abs(dot_product - 1) < epsilon:\n",
    "                group.append(v)\n",
    "                norms[i].append(v_norm)\n",
    "                added_to_group = True\n",
    "                break\n",
    "\n",
    "        # If the current vector has not been added to any group, we create a new group for it\n",
    "        if not added_to_group:\n",
    "            groups.append([v])\n",
    "            norms.append([v_norm])\n",
    "    \n",
    "    for norm in norms:\n",
    "        arr = np.array(norm)\n",
    "        directions.append(np.mean(arr,axis=0))\n",
    "\n",
    "        \n",
    "\n",
    "    return groups,directions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups,directions = group_vectors(weights_history[-1], 0.05)\n",
    "print(len(directions))\n",
    "print([len(group) for group in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_matrix = np.array(directions)\n",
    "np.mean(d_matrix, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def visualize_3d_vectors(matrix):\n",
    "    \"\"\"\n",
    "    Visualize a set of 3D vectors in a 3D plot.\n",
    "\n",
    "    Args:\n",
    "    matrix (np.array): A numpy array where each row is a 3D vector.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an empty figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # For each vector in the matrix, plot a line from the origin to the point defined by the vector\n",
    "    for vector in matrix:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[0, vector[0]],\n",
    "            y=[0, vector[1]],\n",
    "            z=[0, vector[2]],\n",
    "            mode='lines',\n",
    "        ))\n",
    "\n",
    "    # Update layout for better view\n",
    "    fig.update_layout(scene = dict(\n",
    "                    xaxis_title='X',\n",
    "                    yaxis_title='Y',\n",
    "                    zaxis_title='Z'),\n",
    "                    width=700,\n",
    "                    margin=dict(r=20, l=10, b=10, t=10))\n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,S,V = np.linalg.svd(d_matrix)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_3d_vectors(d_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality(directions):\n",
    "    out = []\n",
    "    for w_i in directions:\n",
    "        interference = 0\n",
    "        for w_j in directions:\n",
    "            interference += np.dot(w_i,w_j)**2\n",
    "        out.append(1/interference)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([len(g) for g in groups], dimensionality(directions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(dimensionality(directions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[round(np.mean(normalise(groups[i]),axis=0).T @ np.mean(normalise(groups[j]), axis = 0),4) for j in range(len(groups)) if j != i] for i in range(len(groups))])\n",
    "sorted(a.flatten(), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(a.flatten(), bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dimensionality(directions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([dimensionality(directions), [len(g) for g in groups]]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([model(SyntheticNormalised(f)[i]).argmax() for i in range(f)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
